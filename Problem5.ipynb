{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CWj8jP0h7Rie"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahhassansh/UCF_CAP5610_ML_Assignments/blob/master/Problem5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWj8jP0h7Rie",
        "colab_type": "text"
      },
      "source": [
        "##**Problem 5**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWM9hmXnnVFY",
        "colab_type": "text"
      },
      "source": [
        "###**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DRJWQk2AMQv",
        "colab_type": "code",
        "outputId": "3e2912a4-0703-40a8-8e1f-d20b463e394c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t26wJAxVnbvj",
        "colab_type": "text"
      },
      "source": [
        "###**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZKNQlGzngAr",
        "colab_type": "code",
        "outputId": "59d38a4d-052b-4d26-a6aa-046d8e514fd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(train_images_raw, train_labels_raw), (test_images_raw, test_labels_raw) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 7s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwTQTCpInoQs",
        "colab_type": "text"
      },
      "source": [
        "###**Preparing Images for Number of Region Calculation** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eRzSEvJDUz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = np.zeros((60000,28,28))\n",
        "for counter, a in enumerate(train_images_raw):\n",
        "  for j, b in enumerate(a):\n",
        "    for k,c in enumerate(b):\n",
        "      if (c==0):\n",
        "        train_images[counter,j,k] = 1\n",
        "      elif (c!=0):\n",
        "        train_images[counter,j,k] = 0\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN8lMNHzn1In",
        "colab_type": "text"
      },
      "source": [
        "###**Program for Number of Region Calculation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6odmhGLDFz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Graph: \n",
        "  def __init__(self, row, col, g): \n",
        "    self.ROW = row \n",
        "    self.COL = col \n",
        "    self.graph = g\n",
        "  def isSafe(self, i, j, visited):\n",
        "    return (i >= 0 and i < self.ROW and j >= 0 and j < self.COL and not visited[i][j] and self.graph[i][j])            \n",
        "  def DFS(self, i, j, visited):\n",
        "    rowNbr = [-1, -1, -1,  0, 0,  1, 1, 1]; \n",
        "    colNbr = [-1,  0,  1, -1, 1, -1, 0, 1]; \n",
        "    visited[i][j] = True\n",
        "    for k in range(8):\n",
        "      if self.isSafe(i + rowNbr[k], j + colNbr[k], visited):\n",
        "        self.DFS(i + rowNbr[k], j + colNbr[k], visited) \n",
        "  def countIslands(self):\n",
        "    visited = [[False for j in range(self.COL)]for i in range(self.ROW)] \n",
        "    count = 0\n",
        "    for i in range(self.ROW):\n",
        "      for j in range(self.COL):\n",
        "        if visited[i][j] == False and self.graph[i][j] ==1:\n",
        "          self.DFS(i, j, visited)\n",
        "          count += 1\n",
        "    return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GOyHjVRoB_A",
        "colab_type": "text"
      },
      "source": [
        "###**New Feature Calculation Using Region Calculation Program**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTizgE5AsXlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat = []\n",
        "for a in train_images:\n",
        "  row = len(a)\n",
        "  col = len(a[0])\n",
        "  g = Graph(row, col, a)\n",
        "  feat.append(g.countIslands())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96NHvHB1oL76",
        "colab_type": "text"
      },
      "source": [
        "###**Calculating Accuracy of Number of Regions Cauculated by our Program**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI67Gd6oMCuo",
        "colab_type": "code",
        "outputId": "fbb915ad-8b56-425f-ab91-0b4142061f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "feat2 = [x for x in range(0,60000)]\n",
        "for i in range(0,len(train_labels_raw)):\n",
        "  if train_labels_raw[i] in (1,2,3,4,5,7):\n",
        "    feat2[i] = 1\n",
        "  elif train_labels_raw[i] in (0,6,9):\n",
        "    feat2[i] = 2\n",
        "  elif train_labels_raw[i] == 8:\n",
        "    feat2[i] = 3\n",
        "c = 0\n",
        "for i in range(60000):\n",
        "  if feat[i]== feat2[i]:\n",
        "    c = c+1\n",
        "(c/60000)*100.0\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85.02499999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzLpqYW7p6Xx",
        "colab_type": "text"
      },
      "source": [
        "###**Image Reshaping and Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "876cvVngCsJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images_final = train_images_raw.reshape((60000, 28 * 28))\n",
        "train_images_final = train_images_final.astype('float32') / 255\n",
        "\n",
        "test_images_final = test_images_raw.reshape((10000, 28 * 28))\n",
        "test_images_final = test_images_final.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAX6KxCxGeZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = to_categorical(train_labels_raw)\n",
        "test_labels = to_categorical(test_labels_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZffSKCsqB9f",
        "colab_type": "text"
      },
      "source": [
        "###**Appending New Feature into all images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJyLkN7oRDaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For Train Images\n",
        "xx = len(train_images_final)\n",
        "yy = len(train_images_final[0])\n",
        "tr_im = [[i for i in range(yy+1)] for j in range(xx)]\n",
        "for i in range(0,len(train_images_final)):\n",
        "  for j in range(0,len(train_images_final[i])):\n",
        "    tr_im[i][j] = train_images_final[i][j]\n",
        "  tr_im[i][yy] = feat[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueVoOoYLkBKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For Test Images\n",
        "xx = len(test_images_final)\n",
        "yy = len(test_images_final[0])\n",
        "ts_im = [[i for i in range(yy+1)] for j in range(xx)]\n",
        "for i in range(0,len(test_images_final)):\n",
        "  for j in range(0,len(test_images_final[i])):\n",
        "    ts_im[i][j] = test_images_final[i][j]\n",
        "  ts_im[i][yy] = feat[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqJIZSA79RXh",
        "colab_type": "text"
      },
      "source": [
        "###** Converting List into Numpy Array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD5Q9UuP86gD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_img = np.array(tr_im)\n",
        "ts_img = np.array(ts_im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3KVCskOqUcU",
        "colab_type": "text"
      },
      "source": [
        "###**Network Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14mpx8zPRpAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network = models.Sequential()\n",
        "network.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuyIBLDWqXps",
        "colab_type": "text"
      },
      "source": [
        "###**Compilation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ7gjAfRPi05",
        "colab_type": "code",
        "outputId": "1e4dee81-8d7c-42e9-9dbc-34d9f79baefd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "network.compile(optimizer='Adam',loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFjtPosDqbgj",
        "colab_type": "text"
      },
      "source": [
        "###**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbQPxACDqOjm",
        "colab_type": "code",
        "outputId": "e23128fb-ba84-463c-c6d9-087693ea5ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3658
        }
      },
      "source": [
        "epochs = 100\n",
        "history = network.fit(tr_img, \n",
        "                      train_labels, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=128, \n",
        "                      validation_data=(ts_img, test_labels))\n",
        "network.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.6800 - acc: 0.8327 - val_loss: 0.3997 - val_acc: 0.8972\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.3430 - acc: 0.9086 - val_loss: 0.3377 - val_acc: 0.9062\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2952 - acc: 0.9198 - val_loss: 0.3223 - val_acc: 0.9098\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2712 - acc: 0.9256 - val_loss: 0.3172 - val_acc: 0.9099\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2567 - acc: 0.9297 - val_loss: 0.3226 - val_acc: 0.9061\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2464 - acc: 0.9322 - val_loss: 0.3245 - val_acc: 0.9037\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.2389 - acc: 0.9333 - val_loss: 0.3285 - val_acc: 0.9043\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.2328 - acc: 0.9356 - val_loss: 0.3332 - val_acc: 0.9021\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.2277 - acc: 0.9368 - val_loss: 0.3373 - val_acc: 0.9006\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2238 - acc: 0.9380 - val_loss: 0.3430 - val_acc: 0.8978\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2204 - acc: 0.9387 - val_loss: 0.3452 - val_acc: 0.8966\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2174 - acc: 0.9399 - val_loss: 0.3444 - val_acc: 0.8969\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2143 - acc: 0.9410 - val_loss: 0.3511 - val_acc: 0.8946\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2120 - acc: 0.9413 - val_loss: 0.3553 - val_acc: 0.8924\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2098 - acc: 0.9419 - val_loss: 0.3555 - val_acc: 0.8940\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2078 - acc: 0.9428 - val_loss: 0.3643 - val_acc: 0.8876\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2057 - acc: 0.9434 - val_loss: 0.3633 - val_acc: 0.8885\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2046 - acc: 0.9434 - val_loss: 0.3671 - val_acc: 0.8886\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2026 - acc: 0.9443 - val_loss: 0.3707 - val_acc: 0.8864\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2016 - acc: 0.9441 - val_loss: 0.3777 - val_acc: 0.8861\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2005 - acc: 0.9446 - val_loss: 0.3744 - val_acc: 0.8852\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.1991 - acc: 0.9450 - val_loss: 0.3786 - val_acc: 0.8869\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1978 - acc: 0.9452 - val_loss: 0.3762 - val_acc: 0.8869\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1970 - acc: 0.9459 - val_loss: 0.3826 - val_acc: 0.8830\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1959 - acc: 0.9459 - val_loss: 0.3877 - val_acc: 0.8821\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1950 - acc: 0.9456 - val_loss: 0.3875 - val_acc: 0.8824\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.1940 - acc: 0.9463 - val_loss: 0.3939 - val_acc: 0.8806\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1931 - acc: 0.9464 - val_loss: 0.3874 - val_acc: 0.8822\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1923 - acc: 0.9466 - val_loss: 0.4061 - val_acc: 0.8760\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1918 - acc: 0.9470 - val_loss: 0.3968 - val_acc: 0.8792\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1910 - acc: 0.9473 - val_loss: 0.3979 - val_acc: 0.8791\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1904 - acc: 0.9472 - val_loss: 0.3977 - val_acc: 0.8762\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1897 - acc: 0.9473 - val_loss: 0.4023 - val_acc: 0.8770\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1887 - acc: 0.9473 - val_loss: 0.4131 - val_acc: 0.8737\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1883 - acc: 0.9474 - val_loss: 0.4050 - val_acc: 0.8759\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1878 - acc: 0.9480 - val_loss: 0.4073 - val_acc: 0.8754\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1871 - acc: 0.9478 - val_loss: 0.4126 - val_acc: 0.8763\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1866 - acc: 0.9481 - val_loss: 0.4070 - val_acc: 0.8749\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1860 - acc: 0.9479 - val_loss: 0.4151 - val_acc: 0.8737\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1856 - acc: 0.9486 - val_loss: 0.4139 - val_acc: 0.8741\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1853 - acc: 0.9483 - val_loss: 0.4151 - val_acc: 0.8733\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1850 - acc: 0.9480 - val_loss: 0.4194 - val_acc: 0.8724\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1843 - acc: 0.9487 - val_loss: 0.4217 - val_acc: 0.8721\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1839 - acc: 0.9485 - val_loss: 0.4211 - val_acc: 0.8714\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1838 - acc: 0.9482 - val_loss: 0.4188 - val_acc: 0.8731\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1828 - acc: 0.9490 - val_loss: 0.4209 - val_acc: 0.8722\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1824 - acc: 0.9492 - val_loss: 0.4249 - val_acc: 0.8717\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1823 - acc: 0.9492 - val_loss: 0.4270 - val_acc: 0.8699\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1821 - acc: 0.9491 - val_loss: 0.4307 - val_acc: 0.8691\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1814 - acc: 0.9495 - val_loss: 0.4396 - val_acc: 0.8683\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1813 - acc: 0.9492 - val_loss: 0.4348 - val_acc: 0.8682\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1808 - acc: 0.9495 - val_loss: 0.4373 - val_acc: 0.8678\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1804 - acc: 0.9495 - val_loss: 0.4407 - val_acc: 0.8663\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1800 - acc: 0.9497 - val_loss: 0.4380 - val_acc: 0.8687\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1798 - acc: 0.9502 - val_loss: 0.4431 - val_acc: 0.8650\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1798 - acc: 0.9494 - val_loss: 0.4352 - val_acc: 0.8681\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1791 - acc: 0.9500 - val_loss: 0.4424 - val_acc: 0.8678\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1791 - acc: 0.9499 - val_loss: 0.4406 - val_acc: 0.8683\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1786 - acc: 0.9501 - val_loss: 0.4393 - val_acc: 0.8676\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1785 - acc: 0.9500 - val_loss: 0.4436 - val_acc: 0.8659\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1781 - acc: 0.9501 - val_loss: 0.4484 - val_acc: 0.8664\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1779 - acc: 0.9496 - val_loss: 0.4509 - val_acc: 0.8649\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1777 - acc: 0.9502 - val_loss: 0.4537 - val_acc: 0.8643\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1773 - acc: 0.9501 - val_loss: 0.4506 - val_acc: 0.8652\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1774 - acc: 0.9503 - val_loss: 0.4495 - val_acc: 0.8645\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1767 - acc: 0.9500 - val_loss: 0.4500 - val_acc: 0.8661\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1768 - acc: 0.9507 - val_loss: 0.4476 - val_acc: 0.8658\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1763 - acc: 0.9507 - val_loss: 0.4485 - val_acc: 0.8647\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1762 - acc: 0.9504 - val_loss: 0.4549 - val_acc: 0.8648\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1762 - acc: 0.9504 - val_loss: 0.4522 - val_acc: 0.8643\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1759 - acc: 0.9503 - val_loss: 0.4600 - val_acc: 0.8644\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1756 - acc: 0.9508 - val_loss: 0.4570 - val_acc: 0.8632\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1754 - acc: 0.9507 - val_loss: 0.4626 - val_acc: 0.8619\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1752 - acc: 0.9505 - val_loss: 0.4570 - val_acc: 0.8634\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1750 - acc: 0.9509 - val_loss: 0.4678 - val_acc: 0.8616\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1748 - acc: 0.9510 - val_loss: 0.4656 - val_acc: 0.8618\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1745 - acc: 0.9510 - val_loss: 0.4622 - val_acc: 0.8628\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1743 - acc: 0.9513 - val_loss: 0.4666 - val_acc: 0.8624\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1741 - acc: 0.9509 - val_loss: 0.4612 - val_acc: 0.8647\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1742 - acc: 0.9509 - val_loss: 0.4742 - val_acc: 0.8581\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1739 - acc: 0.9507 - val_loss: 0.4689 - val_acc: 0.8614\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1735 - acc: 0.9509 - val_loss: 0.4707 - val_acc: 0.8607\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1735 - acc: 0.9511 - val_loss: 0.4749 - val_acc: 0.8612\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1736 - acc: 0.9511 - val_loss: 0.4760 - val_acc: 0.8592\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1732 - acc: 0.9510 - val_loss: 0.4690 - val_acc: 0.8617\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1730 - acc: 0.9511 - val_loss: 0.4738 - val_acc: 0.8614\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1729 - acc: 0.9516 - val_loss: 0.4722 - val_acc: 0.8610\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1727 - acc: 0.9515 - val_loss: 0.4713 - val_acc: 0.8616\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1724 - acc: 0.9508 - val_loss: 0.4826 - val_acc: 0.8592\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1724 - acc: 0.9513 - val_loss: 0.4768 - val_acc: 0.8598\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1723 - acc: 0.9513 - val_loss: 0.4847 - val_acc: 0.8568\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1720 - acc: 0.9513 - val_loss: 0.4807 - val_acc: 0.8598\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1718 - acc: 0.9522 - val_loss: 0.4745 - val_acc: 0.8620\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1717 - acc: 0.9511 - val_loss: 0.4802 - val_acc: 0.8594\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1717 - acc: 0.9511 - val_loss: 0.4812 - val_acc: 0.8596\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1716 - acc: 0.9514 - val_loss: 0.4747 - val_acc: 0.8616\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1714 - acc: 0.9516 - val_loss: 0.4839 - val_acc: 0.8597\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1709 - acc: 0.9512 - val_loss: 0.4861 - val_acc: 0.8595\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1711 - acc: 0.9513 - val_loss: 0.4819 - val_acc: 0.8600\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1708 - acc: 0.9521 - val_loss: 0.4853 - val_acc: 0.8600\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 10)                7860      \n",
            "=================================================================\n",
            "Total params: 7,860\n",
            "Trainable params: 7,860\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XJhwPCr-R7g",
        "colab_type": "text"
      },
      "source": [
        "###**History**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewZNeg5K-VAN",
        "colab_type": "code",
        "outputId": "b0e03d30-cc2b-4481-af61-65074792955d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "source": [
        "history.history['acc']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8326666666984558,\n",
              " 0.9085666666984558,\n",
              " 0.9198333333651225,\n",
              " 0.9255666666348775,\n",
              " 0.9297166666666666,\n",
              " 0.93215,\n",
              " 0.9333499999682109,\n",
              " 0.9355666666666667,\n",
              " 0.9367999999682108,\n",
              " 0.9379999999682108,\n",
              " 0.9387166666348775,\n",
              " 0.9399,\n",
              " 0.9410333333333334,\n",
              " 0.9413333333651225,\n",
              " 0.9419333333015442,\n",
              " 0.9427833333333333,\n",
              " 0.9434333333651225,\n",
              " 0.9433666666984558,\n",
              " 0.9443166666348776,\n",
              " 0.9440833333651225,\n",
              " 0.9446000000317891,\n",
              " 0.9449833333333333,\n",
              " 0.94515,\n",
              " 0.9458666666984558,\n",
              " 0.9459333333015442,\n",
              " 0.9456000000317891,\n",
              " 0.9462666666984558,\n",
              " 0.9463500000317892,\n",
              " 0.9465999999682109,\n",
              " 0.9469999999682108,\n",
              " 0.9473166666348776,\n",
              " 0.9472333333651225,\n",
              " 0.9472833333015442,\n",
              " 0.94725,\n",
              " 0.9474333333333333,\n",
              " 0.948,\n",
              " 0.9477666666666666,\n",
              " 0.9480833333333333,\n",
              " 0.9479166666984558,\n",
              " 0.9485666666348775,\n",
              " 0.9482833333015442,\n",
              " 0.9479666666348775,\n",
              " 0.9486833333333333,\n",
              " 0.9485166666348775,\n",
              " 0.9482333333015441,\n",
              " 0.9490333333651225,\n",
              " 0.9491833333651225,\n",
              " 0.9492499999682109,\n",
              " 0.94915,\n",
              " 0.9495,\n",
              " 0.9491500000317892,\n",
              " 0.9495166666984558,\n",
              " 0.9494999999682109,\n",
              " 0.9496666666666667,\n",
              " 0.9502333333015441,\n",
              " 0.9493833333333334,\n",
              " 0.9499999999682108,\n",
              " 0.9499,\n",
              " 0.9501,\n",
              " 0.9499833333015442,\n",
              " 0.9500666666666666,\n",
              " 0.9495666666666667,\n",
              " 0.9502166666984558,\n",
              " 0.9501166666666667,\n",
              " 0.9503333333015442,\n",
              " 0.9499666666348775,\n",
              " 0.9506666666666667,\n",
              " 0.9506666666984558,\n",
              " 0.9504166666984558,\n",
              " 0.9503833333015442,\n",
              " 0.9503166666348776,\n",
              " 0.9507833333333333,\n",
              " 0.9507333333015442,\n",
              " 0.9505499999682109,\n",
              " 0.95085,\n",
              " 0.9510499999682108,\n",
              " 0.9509666666348775,\n",
              " 0.9512999999682109,\n",
              " 0.9509,\n",
              " 0.95085,\n",
              " 0.9507000000317891,\n",
              " 0.95095,\n",
              " 0.9510666666348775,\n",
              " 0.9510666666666666,\n",
              " 0.9510333333651225,\n",
              " 0.9510999999682108,\n",
              " 0.9515500000317891,\n",
              " 0.9515,\n",
              " 0.9508166666666666,\n",
              " 0.9513,\n",
              " 0.9513166666666667,\n",
              " 0.9512833333015442,\n",
              " 0.9521666666666667,\n",
              " 0.9510833333651225,\n",
              " 0.9510500000317892,\n",
              " 0.9513833333015442,\n",
              " 0.9516166666348775,\n",
              " 0.9511999999682108,\n",
              " 0.9513,\n",
              " 0.9521166666348775]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}